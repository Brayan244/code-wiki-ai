{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting UP credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
    "os.environ['ACTIVELOOP_TOKEN'] = 'ACTIVELOOP_TOKEN'\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing the repository\n",
    "\n",
    "## Cloning the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!git clone git@github.com:reservamos/vanda-admin.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load repo files to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 980 documents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "root_dir = './vanda-admin'\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass\n",
    "\n",
    "print(\"Loaded {} documents\".format(len(docs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1593, which is longer than the specified 1000\n",
      "Created a chunk of size 1419, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1591, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 2802, which is longer than the specified 1000\n",
      "Created a chunk of size 1653, which is longer than the specified 1000\n",
      "Created a chunk of size 1649, which is longer than the specified 1000\n",
      "Created a chunk of size 2085, which is longer than the specified 1000\n",
      "Created a chunk of size 1669, which is longer than the specified 1000\n",
      "Created a chunk of size 2968, which is longer than the specified 1000\n",
      "Created a chunk of size 2473, which is longer than the specified 1000\n",
      "Created a chunk of size 2417, which is longer than the specified 1000\n",
      "Created a chunk of size 2114, which is longer than the specified 1000\n",
      "Created a chunk of size 1601, which is longer than the specified 1000\n",
      "Created a chunk of size 3379, which is longer than the specified 1000\n",
      "Created a chunk of size 2485, which is longer than the specified 1000\n",
      "Created a chunk of size 1412, which is longer than the specified 1000\n",
      "Created a chunk of size 1684, which is longer than the specified 1000\n",
      "Created a chunk of size 2543, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1332, which is longer than the specified 1000\n",
      "Created a chunk of size 1774, which is longer than the specified 1000\n",
      "Created a chunk of size 1071, which is longer than the specified 1000\n",
      "Created a chunk of size 1026, which is longer than the specified 1000\n",
      "Created a chunk of size 1399, which is longer than the specified 1000\n",
      "Created a chunk of size 2894, which is longer than the specified 1000\n",
      "Created a chunk of size 1131, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1350, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1451, which is longer than the specified 1000\n",
      "Created a chunk of size 2655, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 1020, which is longer than the specified 1000\n",
      "Created a chunk of size 1540, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/brayan244/code-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://brayan244/code-dataset loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 3/3 [00:43<00:00\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://brayan244/code-dataset', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape       dtype  compression\n",
      "  -------   -------    -------     -------  ------- \n",
      " embedding  generic  (2112, 1536)  float32   None   \n",
      "    ids      text     (2112, 1)      str     None   \n",
      " metadata    json     (2112, 1)      str     None   \n",
      "   text      text     (2112, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "deeplake_path = 'hub://brayan244/code-dataset'\n",
    "\n",
    "db = DeepLake.from_documents(texts, embeddings, dataset_path=deeplake_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/brayan244/code-dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://brayan244/code-dataset loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://brayan244/code-dataset already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://brayan244/code-dataset', read_only=True, tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape       dtype  compression\n",
      "  -------   -------    -------     -------  ------- \n",
      " embedding  generic  (2112, 1536)  float32   None   \n",
      "    ids      text     (2112, 1)      str     None   \n",
      " metadata    json     (2112, 1)      str     None   \n",
      "   text      text     (2112, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "deeplake_path = 'hub://brayan244/code-dataset'\n",
    "db = DeepLake(dataset_path=deeplake_path, read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: give me all the database fields for a payment \n",
      "\n",
      "**Answer**: Here are all the database fields for a payment:\n",
      "\n",
      "From the `AddPayments` migration:\n",
      "- `id: integer` - the ID of the payment (primary key)\n",
      "- `purchase_id: integer` - the ID of the purchase associated with the payment\n",
      "- `state: string` - the state of the payment\n",
      "- `credit_card_token: string` - the token of the credit card used for the payment\n",
      "- `amount: decimal` - the amount of the payment\n",
      "- `complete_payment: boolean` - whether the payment has been completed or not\n",
      "- `created_at: datetime` - the timestamp of when the payment was created\n",
      "- `updated_at: datetime` - the timestamp of when the payment was last updated\n",
      "\n",
      "From the `AddPayPalFieldsToPayment` migration:\n",
      "- `paypal_email: string` - the email associated with the PayPal account used for the payment\n",
      "- `paypal_verified: boolean` - whether the PayPal account used for the payment is verified or not\n",
      "- `paypal_payer_id: string` - the ID of the PayPal account used for the payment\n",
      "- `paypal_payer_status: string` - the status of the PayPal account used for the payment\n",
      "- `paypal_payer_address_status: string` - the address status of the PayPal account used for the payment\n",
      "- `paypal_insurance_option_offered: boolean` - whether insurance options are offered for the payment through PayPal\n",
      "\n",
      "From the `AddConektaFieldsToPayment` migration:\n",
      "- `reference: string` - the reference for the payment\n",
      "- `expiration_date: datetime` - the expiration date for the payment\n",
      "- `fee: float` - the fee for the payment\n",
      "- `raw_confirmation: text` - the raw confirmation data for the payment\n",
      "- `error_message: string` - the error message associated with the payment, if any\n",
      "- `error_backtrace: text` - the error backtrace associated with the payment, if any\n",
      "- `error_code: integer` - the error code associated with the payment, if any\n",
      "\n",
      "From the `AddPaypalFieldToPayment` migration:\n",
      "- `paypal_transaction_id: string` - the PayPal transaction ID associated with the payment\n",
      "\n",
      "From the `AddAdyenFieldsToPayments` migration:\n",
      "- `payment_token: string` - the token associated with the payment\n",
      "- `card_holder_name: string` - the name of the cardholder associated with the payment\n",
      "- `paid_at: datetime` - the timestamp of when the payment was made\n",
      "- `purchaser_ip: string` - the IP address of the purchaser associated with the payment\n",
      "- `engine_response: hstore` - additional response data from the payment engine\n",
      "\n",
      "From the `AddHstoreToPayments` migration:\n",
      "- `browser_info: hstore` - information about the browser used for the payment\n",
      "- `adyen_payment_data: text` - additional payment data from Adyen\n",
      "- `adyen_md: text` - additional metadata from Adyen\n",
      "- `adyen_pa_req: text` - additional payment request data from Adyen\n",
      "- `adyen_url: text` - the URL used for the payment through Adyen\n",
      "- `adyen_term_url: text` - the URL for the payment terminal used through Adyen\n",
      "- `redirect_url: text` - the redirect URL for the payment\n",
      "- `use_3d_secure: boolean` - whether 3D Secure was used for the payment or not\n",
      "\n",
      "From the `AddColumnsToPayments` migration:\n",
      "- `refusal_code: string` - the code associated with a payment refusal, if applicable\n",
      "- `refusal_message: string` - the message associated with a payment refusal, if applicable\n",
      "\n",
      "The actual fields used in a payment may vary depending on the payment engine used and other factors. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo') # 'gpt-3.5-turbo',\n",
    "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)\n",
    "\n",
    "questions = [\n",
    "    \"give me all the database fields for a payment\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
